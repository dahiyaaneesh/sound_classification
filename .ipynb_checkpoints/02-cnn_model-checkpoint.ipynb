{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64,2,1),\n",
    "#             nn.MaxPool2d(2,1),\n",
    "            nn.Conv2d(64, 128, 2,1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(13056,10)\n",
    "            ,\n",
    "            nn.Softmax(1))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return torch.max(x, axis=1)[0]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch['features'],\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)    \n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log('val_loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LitAutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (1): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Flatten(start_dim=1, end_dim=-1)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=13056, out_features=10, bias=True)\n",
       "    (6): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4037], grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(data[0][\"features\"].reshape(1,1,36,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13056*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/media/aneesh/USB1000/Zurich_Urban_Sounds\"\n",
    "RECORDER = \"TASCAM_RECORDER\"\n",
    "SEGMENT_DIR = \"audio_segments\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class unlabeled_audio_segments(Dataset):\n",
    "    \n",
    "    def __init__(self, file_list_path, feature_dir):\n",
    "\n",
    "        self.file_list_path= file_list_path\n",
    "        self.feature_dir = feature_dir\n",
    "        self.filenames = pd.read_csv(file_list_path)\n",
    "        self.filenames[\"features\"] = self.filenames[\"Non_silent_segments\"].apply(\n",
    "            lambda x :  x.replace(\".wav\", \".npy\")\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample = {'features':torch.from_numpy(\n",
    "            np.load(\n",
    "                os.path.join(self.feature_dir,\n",
    "                             self.filenames[\"features\"].iloc[idx]\n",
    "                            )).squeeze())\n",
    "                 }\n",
    "\n",
    "        return sample  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class labeled_audio_segments(Dataset):\n",
    "    def __init__(self, features_path, labels_path):\n",
    "\n",
    "        self.labels = pd.read_csv(labels_path)\n",
    "        self.features = pd.read_csv(features_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample = {'features':torch.Tensor((self.features.iloc[idx].values.reshape(36,5)).astype(np.float32)),\n",
    "                  'labels':torch.tensor(self.labels.iloc[idx].values.astype(np.float32)[0])\n",
    "                 }\n",
    "\n",
    "        return sample  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = labeled_audio_segments('/media/aneesh/USB1000/Zurich_Urban_Sounds/train_data.csv', '/media/aneesh/USB1000/Zurich_Urban_Sounds/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': tensor([[-4.1729e+02,  1.0015e+02, -4.3869e+01,  5.1953e+01,  9.0444e+00],\n",
       "         [ 8.7802e+00,  1.0376e+01,  2.7314e+00,  6.1753e+00,  5.0651e+00],\n",
       "         [-4.3707e+00,  1.4676e+01, -3.5300e+00,  8.0437e+00,  4.8215e+00],\n",
       "         [ 2.6133e+00,  1.0506e+00,  7.7588e+00, -3.1388e+00,  4.1032e+00],\n",
       "         [-5.6389e-01,  6.8306e+00, -8.0799e-01,  7.2286e+00, -7.9898e-01],\n",
       "         [ 7.5396e-01, -4.1683e+00,  1.2598e+00, -6.3962e+00,  1.3227e+00],\n",
       "         [-1.6741e+00,  2.7055e+00, -1.9224e+00,  1.1593e+00, -1.2142e+00],\n",
       "         [ 1.2042e+00,  3.4982e-02,  8.0266e-03,  2.7767e-03,  3.1436e-03],\n",
       "         [ 2.7485e-03,  1.3418e-03,  1.6905e-03,  1.4311e-03,  6.4932e-04],\n",
       "         [ 1.0004e-03,  1.3613e-03,  6.8252e-04,  1.0383e-03,  1.9018e-03],\n",
       "         [ 1.6610e-03,  9.6201e-04,  1.2086e-03,  3.0248e-03,  4.7647e-03],\n",
       "         [ 2.7041e-03,  2.7041e-03,  2.0084e-03,  2.9568e-03,  4.8983e-03],\n",
       "         [ 2.7465e-03,  6.9050e-04,  5.8380e-04,  7.7438e-04,  7.5575e-04],\n",
       "         [ 3.5992e-04,  1.5112e-04,  2.3885e-05,  1.2700e-05,  7.9286e-06],\n",
       "         [ 7.0376e-06,  6.3925e-06,  3.3185e-01,  2.9948e-01,  3.0573e-01],\n",
       "         [ 3.3106e-01,  3.1571e-01,  3.1481e-01,  3.1526e-01,  3.4031e-01],\n",
       "         [ 3.3565e-01,  2.9513e-01,  3.1019e-01,  3.6747e-01,  3.9201e-01],\n",
       "         [ 3.7069e-01,  3.4764e-01,  3.5489e-01,  3.5935e-01,  3.8839e-01],\n",
       "         [ 3.8676e-01,  3.7342e-01,  3.8192e-01,  3.9767e-01,  3.9680e-01],\n",
       "         [ 3.8444e-01,  3.2498e-01,  3.0310e-01,  3.3172e-01,  3.2629e-01],\n",
       "         [ 3.4646e-01,  3.6972e-01,  3.7068e-01,  3.5721e-01,  3.8066e-01],\n",
       "         [ 3.7696e-01,  3.9762e-01,  3.4858e-01,  4.7274e-01,  5.5476e-01],\n",
       "         [ 6.0608e-01,  5.5627e-01,  6.1241e-01,  6.0163e-01,  6.2090e-01],\n",
       "         [ 6.1913e-01,  6.0509e-01,  6.2328e-01,  5.5744e-01,  5.8060e-01],\n",
       "         [ 6.0482e-01,  6.4672e-01,  6.7885e-01,  6.3739e-01,  6.3456e-01],\n",
       "         [ 6.4935e-01,  6.1259e-01,  5.5615e-01,  5.4518e-01,  6.1492e-01],\n",
       "         [ 6.0842e-01,  5.9411e-01,  5.9476e-01,  7.0005e-01,  5.7075e-01],\n",
       "         [ 4.9692e-01,  5.1670e-01,  6.1000e-01,  6.0660e-01,  5.4410e-01],\n",
       "         [ 4.8393e-01,  4.3918e-01,  3.8873e-01,  3.5226e-01,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  7.5016e-02,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0819e-01,  2.0530e-01,  1.3944e-01],\n",
       "         [ 9.2667e-02,  4.3889e-02,  3.0009e-02,  0.0000e+00,  1.0347e-01],\n",
       "         [ 2.3779e-01,  1.4224e-01,  8.9201e-02,  0.0000e+00,  2.4169e-01],\n",
       "         [ 5.8639e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]),\n",
       " 'labels': tensor(2.)}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = DataLoader(data, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = unlabeled_audio_segments(os.path.join(BASE_PATH, RECORDER, \"non_silent_segment.csv\"),\n",
    "                        os.path.join(BASE_PATH, RECORDER, \"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Non_silent_segments</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2_000000051.wav</td>\n",
       "      <td>2_000000051.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2_000000052.wav</td>\n",
       "      <td>2_000000052.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2_000000053.wav</td>\n",
       "      <td>2_000000053.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2_000000086.wav</td>\n",
       "      <td>2_000000086.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2_000000112.wav</td>\n",
       "      <td>2_000000112.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>4607</td>\n",
       "      <td>12_000003802.wav</td>\n",
       "      <td>12_000003802.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>4608</td>\n",
       "      <td>12_000003971.wav</td>\n",
       "      <td>12_000003971.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>4609</td>\n",
       "      <td>12_000003972.wav</td>\n",
       "      <td>12_000003972.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>4610</td>\n",
       "      <td>12_000003992.wav</td>\n",
       "      <td>12_000003992.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>4611</td>\n",
       "      <td>12_000003993.wav</td>\n",
       "      <td>12_000003993.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4612 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Non_silent_segments          features\n",
       "0              0     2_000000051.wav   2_000000051.npy\n",
       "1              1     2_000000052.wav   2_000000052.npy\n",
       "2              2     2_000000053.wav   2_000000053.npy\n",
       "3              3     2_000000086.wav   2_000000086.npy\n",
       "4              4     2_000000112.wav   2_000000112.npy\n",
       "...          ...                 ...               ...\n",
       "4607        4607    12_000003802.wav  12_000003802.npy\n",
       "4608        4608    12_000003971.wav  12_000003971.npy\n",
       "4609        4609    12_000003972.wav  12_000003972.npy\n",
       "4610        4610    12_000003992.wav  12_000003992.npy\n",
       "4611        4611    12_000003993.wav  12_000003993.npy\n",
       "\n",
       "[4612 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
